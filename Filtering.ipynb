{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1ba03aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "\n",
    "import math\n",
    "from itertools import combinations, permutations, product\n",
    "from typing import List, Union\n",
    "\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "import numpy as np\n",
    "from medimage import image as MEDimage\n",
    "\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "# !pip install medimage\n",
    "import SimpleITK as sitk\n",
    "from scipy.ndimage import convolve as scipy_convolve\n",
    "\n",
    "from abc import ABC\n",
    "from medimage import image as MEDimage\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b171000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class image_volume_obj:\n",
    "    def __init__(self, data: np.ndarray):\n",
    "        self.data = data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "683de5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_imgs(\n",
    "            images: np.ndarray,\n",
    "            padding_length: List,\n",
    "            axis: List,\n",
    "            mode: str\n",
    "            )-> np.ndarray:\n",
    "    \"\"\"Apply padding on a 3d images using a 2D padding pattern.\n",
    "\n",
    "    Args:\n",
    "        images (ndarray): a numpy array that represent the image.\n",
    "        padding_length (List): The padding length that will apply on each side of each axe.\n",
    "        axis (List): A list of axes on which the padding will be done.\n",
    "        mode (str): The padding mode. Check options here: `numpy.pad \n",
    "            <https://numpy.org/doc/stable/reference/generated/numpy.pad.html>`__.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: A numpy array that represent the padded image.\n",
    "    \"\"\"\n",
    "    pad_tuple = ()\n",
    "    j = 1\n",
    "\n",
    "    for i in range(np.ndim(images)):\n",
    "        if i in axis:\n",
    "            pad_tuple += ((padding_length[-j], padding_length[-j]),)\n",
    "            j += 1\n",
    "        else:\n",
    "            pad_tuple += ((0, 0),)\n",
    "\n",
    "    return np.pad(images, pad_tuple, mode=mode)\n",
    "\n",
    "def convolve(\n",
    "        dim: int,\n",
    "        kernel: np.ndarray,\n",
    "        images: np.ndarray,\n",
    "        orthogonal_rot: bool=False,\n",
    "        mode: str = \"symmetric\"\n",
    "    ) -> np.ndarray:\n",
    "    \"\"\"Convolve a given n-dimensional array with the kernel to generate a filtered image.\n",
    "\n",
    "    Args:\n",
    "        dim (int): The dimension of the images.\n",
    "        kernel (ndarray): The kernel to use for the convolution.\n",
    "        images (ndarray): A n-dimensional numpy array that represent a batch of images to filter.\n",
    "        orthogonal_rot (bool, optional): If true, the 3D images will be rotated over coronal, axial and sagittal axis.\n",
    "        mode (str, optional): The padding mode. Check options here: `numpy.pad \n",
    "            <https://numpy.org/doc/stable/reference/generated/numpy.pad.html>`__.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: The filtered image.\n",
    "    \"\"\"\n",
    "\n",
    "    in_size = np.shape(images)\n",
    "\n",
    "    # We only handle 2D or 3D images.\n",
    "    assert len(in_size) == 3 or len(in_size) == 4, \\\n",
    "        \"The tensor should have the followed shape (B, H, W) or (B, D, H, W)\"\n",
    "\n",
    "    if not orthogonal_rot:\n",
    "        # If we have a 2D kernel but a 3D images, we squeeze the tensor\n",
    "        if dim < len(in_size) - 1:\n",
    "            images = images.reshape((in_size[0] * in_size[1], in_size[2], in_size[3]))\n",
    "\n",
    "        # We compute the padding size along each dimension\n",
    "        padding = [int((kernel.shape[-1] - 1) / 2) for _ in range(dim)]\n",
    "        pad_axis_list = [i for i in range(1, dim+1)]\n",
    "\n",
    "        # We pad the images and we add the channel axis.\n",
    "        padded_imgs = pad_imgs(images, padding, pad_axis_list, mode)\n",
    "        new_imgs = np.expand_dims(padded_imgs, axis=1)\n",
    "\n",
    "        # Operate the convolution\n",
    "        if dim < len(in_size) - 1:\n",
    "            # If we have a 2D kernel but a 3D images, we convolve slice by slice\n",
    "            result_list = [fftconvolve(np.expand_dims(new_imgs[i], axis=0), kernel, mode='valid') for i in range(len(images))]\n",
    "            result = np.squeeze(np.stack(result_list), axis=2)\n",
    "\n",
    "        else :\n",
    "            result = fftconvolve(new_imgs, kernel, mode='valid')\n",
    "\n",
    "        # Reshape the data to retrieve the following format: (B, C, D, H, W)\n",
    "        if dim < len(in_size) - 1:\n",
    "            result = result.reshape((\n",
    "                in_size[0], in_size[1], result.shape[1], in_size[2], in_size[3])\n",
    "            ).transpose(0, 2, 1, 3, 4)\n",
    "\n",
    "    # If we want orthogonal rotation\n",
    "    else:\n",
    "        coronal_imgs = images\n",
    "        axial_imgs, sagittal_imgs = np.rot90(images, 1, (1, 2)), np.rot90(images, 1, (1, 3))\n",
    "        \n",
    "        result_coronal = convolve(dim, kernel, coronal_imgs, False, mode)\n",
    "        result_axial = convolve(dim, kernel, axial_imgs, False, mode)\n",
    "        result_sagittal = convolve(dim, kernel, sagittal_imgs, False, mode)\n",
    "\n",
    "        # split and unflip and stack the result on a new axis\n",
    "        result_axial = np.rot90(result_axial, 1, (3, 2))\n",
    "        result_sagittal = np.rot90(result_sagittal, 1, (4, 2))\n",
    "\n",
    "        result = np.stack([result_coronal, result_axial, result_sagittal])\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "5808969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filtering:\n",
    "    \"\"\"Class to handle various filtering operations on imaging data.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "        \n",
    "    def average_pooling(self, image, pool_size=(2, 2, 2), strides=None):\n",
    "        \"\"\"\n",
    "        Apply 3D average pooling to the input image.\n",
    "\n",
    "        Parameters:\n",
    "        image (np.array): 3D array representing the image to be pooled.\n",
    "        pool_size (tuple): Size of the pooling window (default: (2, 2, 2)).\n",
    "        strides (tuple): Strides for the pooling operation (default: same as pool_size).\n",
    "\n",
    "        Returns:\n",
    "        np.array: Average-pooled 3D image.\n",
    "        \"\"\"\n",
    "        if strides is None:\n",
    "            strides = pool_size\n",
    "        depth, height, width = image.shape\n",
    "\n",
    "        out_depth = (depth - pool_size[0]) // strides[0] + 1\n",
    "        out_height = (height - pool_size[1]) // strides[1] + 1\n",
    "        out_width = (width - pool_size[2]) // strides[2] + 1\n",
    "\n",
    "        pooled_image = np.zeros((out_depth, out_height, out_width))\n",
    "\n",
    "        for d in range(out_depth):\n",
    "            for h in range(out_height):\n",
    "                for w in range(out_width):\n",
    "                    start_d = d * strides[0]\n",
    "                    start_h = h * strides[1]\n",
    "                    start_w = w * strides[2]\n",
    "\n",
    "                    end_d = start_d + pool_size[0]\n",
    "                    end_h = start_h + pool_size[1]\n",
    "                    end_w = start_w + pool_size[2]\n",
    "\n",
    "                    pooled_image[d, h, w] = np.mean(image[start_d:end_d, start_h:end_h, start_w:end_w])\n",
    "\n",
    "        return pooled_image\n",
    "\n",
    "    def max_pooling(self, image, pool_size=(2, 2, 2), strides=None):\n",
    "        \"\"\"\n",
    "        Apply 3D max pooling to the input image.\n",
    "\n",
    "        Parameters:\n",
    "        image (np.array): 3D array representing the image to be pooled.\n",
    "        pool_size (tuple): Size of the pooling window (default: (2, 2, 2)).\n",
    "        strides (tuple): Strides for the pooling operation (default: same as pool_size).\n",
    "\n",
    "        Returns:\n",
    "        np.array: Max-pooled 3D image.\n",
    "        \"\"\"\n",
    "        if strides is None:\n",
    "            strides = pool_size\n",
    "        depth, height, width = image.shape\n",
    "\n",
    "        out_depth = (depth - pool_size[0]) // strides[0] + 1\n",
    "        out_height = (height - pool_size[1]) // strides[1] + 1\n",
    "        out_width = (width - pool_size[2]) // strides[2] + 1\n",
    "\n",
    "        pooled_image = np.zeros((out_depth, out_height, out_width))\n",
    "\n",
    "        for d in range(out_depth):\n",
    "            for h in range(out_height):\n",
    "                for w in range(out_width):\n",
    "                    start_d = d * strides[0]\n",
    "                    start_h = h * strides[1]\n",
    "                    start_w = w * strides[2]\n",
    "\n",
    "                    end_d = start_d + pool_size[0]\n",
    "                    end_h = start_h + pool_size[1]\n",
    "                    end_w = start_w + pool_size[2]\n",
    "\n",
    "                    pooled_image[d, h, w] = np.max(image[start_d:end_d, start_h:end_h, start_w:end_w])\n",
    "\n",
    "        return pooled_image\n",
    "    \n",
    "    def upsample3d(self, image, output_shape):\n",
    "        zoom_factors = np.array(output_shape) / np.array(image.shape)\n",
    "        return scipy.ndimage.zoom(image, zoom_factors, order=3)\n",
    "\n",
    "\n",
    "    \n",
    "    def mean_filter(self, ndims: int, size: int, images: np.ndarray, orthogonal_rot: bool = False, padding=\"symmetric\") -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply mean filtering to the input images.\n",
    "\n",
    "        Args:\n",
    "            ndims (int): Number of dimensions of the kernel filter.\n",
    "            size (int): An integer that represents the length along one dimension of the kernel.\n",
    "            padding (str): The padding type that will be used to produce the convolution.\n",
    "            images (np.ndarray): A n-dimensional numpy array that represents the images to filter.\n",
    "            orthogonal_rot (bool, optional): If true, the 3D images will be rotated over coronal, axial and sagittal axes.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The filtered image.\n",
    "        \"\"\"\n",
    "        assert isinstance(ndims, int) and ndims > 0, \"ndims should be a positive integer\"\n",
    "        assert ((size + 1) / 2).is_integer() and size > 0, \"size should be a positive odd number.\"\n",
    "\n",
    "        # Initialize the kernel as a tensor of zeros\n",
    "        weight = 1 / np.prod(size ** ndims)\n",
    "        kernel = np.ones([size for _ in range(ndims)]) * weight\n",
    "        kernel = np.expand_dims(kernel, axis=(0, 1))\n",
    "\n",
    "        # Ensure images is at least 4-dimensional (B, W, H, D)\n",
    "        if images.ndim < 4:\n",
    "            raise ValueError(\"Input images must have at least 4 dimensions (B, W, H, D)\")\n",
    "\n",
    "        # Swap the second axis with the last, to convert image B, W, H, D --> B, D, H, W\n",
    "        image = np.swapaxes(images, 1, 3)\n",
    "        result = np.squeeze(convolve(ndims, kernel, image, orthogonal_rot, padding), axis=1)\n",
    "        \n",
    "        return np.swapaxes(result, 1, 3)\n",
    "    \n",
    "    def mean_filtering(self, input_images: Union[np.ndarray, sitk.Image], ndims: int = 3, size: int = 15, orthogonal_rot: bool = False, padding: str = \"symmetric\") -> np.ndarray:\n",
    "        \"\"\"Apply mean filtering to the input images.\"\"\"\n",
    "        if isinstance(input_images, sitk.Image):\n",
    "            input_images = sitk.GetArrayFromImage(input_images)\n",
    "\n",
    "        input_images = np.expand_dims(input_images.astype(np.float64), axis=0)\n",
    "        \n",
    "        result = self.mean_filter(ndims, size, input_images, orthogonal_rot, padding)\n",
    "        \n",
    "        return np.squeeze(result)\n",
    "    \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    def log_filter(self, ndims:int, size: int, images: np.ndarray, sigma: float, orthogonal_rot: bool = False, padding=\"constant\") -> np.ndarray:\n",
    "        \"\"\"The constructor of the laplacian of gaussian (LoG) filter\n",
    "\n",
    "        Args:\n",
    "            ndims (int): Number of dimension of the kernel filter\n",
    "            size (int): An integer that represent the length along one dimension of the kernel.\n",
    "            sigma (float): The gaussian standard deviation parameter of the laplacian of gaussian filter\n",
    "            padding (str): The padding type that will be used to produce the convolution\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        assert isinstance(ndims, int) and ndims > 0, \"ndims should be a positive integer\"\n",
    "#         assert ((size+1)/2).is_integer() and size > 0, \"size should be a positive odd number.\"\n",
    "        assert sigma > 0, \"alpha should be a positive float.\"\n",
    "        self.dim = ndims\n",
    "        self.size = size\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        def compute_weight(position):\n",
    "            distance_2 = np.sum(position**2)\n",
    "            first_part = -1/((2*math.pi)**(self.dim/2) * self.sigma**(self.dim+2))\n",
    "            second_part = (self.dim - distance_2/self.sigma**2)*math.e**(-distance_2/(2 * self.sigma**2))\n",
    "\n",
    "            return first_part * second_part\n",
    "\n",
    "        kernel = np.zeros([self.size for _ in range(self.dim)])\n",
    "\n",
    "        for k in product(range(self.size), repeat=self.dim):\n",
    "            kernel[k] = compute_weight(np.array(k)-int((self.size-1)/2))\n",
    "\n",
    "        kernel -= np.sum(kernel)/np.prod(kernel.shape)\n",
    "        kernel = np.expand_dims(kernel, axis=(0, 1))\n",
    "            \n",
    "        print(kernel.shape)\n",
    "\n",
    "        image = np.swapaxes(images, 1, 3)\n",
    "        print(image.shape)\n",
    "        result = np.squeeze(convolve(ndims, kernel, image, orthogonal_rot, padding), axis=1)\n",
    "        \n",
    "        return np.swapaxes(result, 1, 3)\n",
    "        \n",
    "\n",
    "    def log_filtering(self, input_images:Union[np.ndarray, sitk.Image], ndims: int = 3, size: int = 15, sigma: int = 3, orthogonal_rot: bool = False, padding: str = \"symmetric\") -> np.ndarray:\n",
    "        \n",
    "        if isinstance(input_images, sitk.Image):\n",
    "            input_images = sitk.GetArrayFromImage(input_images)\n",
    "\n",
    "        input_images = np.expand_dims(input_images.astype(np.float64), axis=0)\n",
    "        \n",
    "        result = self.log_filter(ndims, size, input_images, sigma, orthogonal_rot, padding)\n",
    "        \n",
    "        return np.squeeze(result)\n",
    "        \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "   \n",
    "    def gabor_filter(self, ndims:int, size: int, images: np.ndarray, sigma: float, lamb: float, gamma: float, theta= float, orthogonal_rot: bool = False, padding= \"constant\") -> np.ndarray:\n",
    "        \"\"\"\n",
    "        The constructor of the Gabor filter. Highly inspired by Ref 1.\n",
    "\n",
    "        Args:\n",
    "            size (int): An integer that represent the length along one dimension of the kernel.\n",
    "            sigma (float): A positive float that represent the scale of the Gabor filter\n",
    "            lamb (float): A positive float that represent the wavelength in the Gabor filter. (mm or pixel?)\n",
    "            gamma (float): A positive float that represent the spacial aspect ratio\n",
    "            theta (float): Angle parameter used in the rotation matrix\n",
    "            rot_invariance (bool): If true, rotation invariance will be done on the kernel and the kernel\n",
    "                                   will be rotate 2*pi / theta times.\n",
    "            padding: The padding type that will be used to produce the convolution\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        \n",
    "        assert ((size + 1) / 2).is_integer() and size > 0, \"size should be a positive odd number.\"\n",
    "        assert sigma > 0, \"sigma should be a positive float\"\n",
    "        assert lamb > 0, \"lamb represent the wavelength, so it should be a positive float\"\n",
    "        assert gamma > 0, \"gamma is the ellipticity of the support of the filter, so it should be a positive float\"\n",
    "\n",
    "        self.dim = ndims\n",
    "        self.padding = padding\n",
    "        self.size = size\n",
    "        self.sigma = sigma\n",
    "        self.lamb = lamb\n",
    "        self.gamma = gamma\n",
    "        self.theta = theta\n",
    "        self.rot = orthogonal_rot\n",
    "        \n",
    "        def compute_weight(position, theta):\n",
    "            k_2 = position[0]*math.cos(theta) + position[1] * math.sin(theta)\n",
    "            k_1 = position[1]*math.cos(theta) - position[0] * math.sin(theta)\n",
    "\n",
    "            common = math.e**(-(k_1**2 + (self.gamma*k_2)**2)/(2*self.sigma**2))\n",
    "            real = math.cos(2*math.pi*k_1/self.lamb)\n",
    "            im = math.sin(2*math.pi*k_1/self.lamb)\n",
    "            return common*real, common*im\n",
    "        \n",
    "        # Rotation invariance\n",
    "        nb_rot = round(2*math.pi/abs(self.theta)) if self.rot else 1\n",
    "        real_list = []\n",
    "        im_list = []\n",
    "\n",
    "        for i in range(1, nb_rot+1):\n",
    "            # Initialize the kernel as tensor of zeros\n",
    "            real_kernel = np.zeros([self.size for _ in range(2)])\n",
    "            im_kernel = np.zeros([self.size for _ in range(2)])\n",
    "\n",
    "            for k in product(range(self.size), repeat=2):\n",
    "                real_kernel[k], im_kernel[k] = compute_weight(np.array(k)-int((self.size-1)/2), self.theta*i)\n",
    "\n",
    "            real_list.extend([real_kernel])\n",
    "            im_list.extend([im_kernel])\n",
    "\n",
    "        kernel = np.expand_dims(np.concatenate((real_list, im_list), axis=0), axis=1)\n",
    "        # Ensure images is at least 4-dimensional (B, W, H, D)\n",
    "        if images.ndim < 4:\n",
    "            raise ValueError(\"Input images must have at least 4 dimensions (B, W, H, D)\")\n",
    "\n",
    "        image = np.swapaxes(images, 1, 3)\n",
    "\n",
    "#         result = convolve(self.dim, kernel, image, orthogonal_rot, self.padding)\n",
    "        result = convolve(ndims, kernel, image, orthogonal_rot, padding)\n",
    "        # Reshape to get real and imaginary response on the first axis.\n",
    "        _dim = 2 if orthogonal_rot else 1\n",
    "        nb_rot = int(result.shape[_dim]/2)\n",
    "        result = np.stack(np.array_split(result, np.array([nb_rot]), _dim), axis=0)\n",
    "\n",
    "        # 2D modulus response map\n",
    "        result = np.linalg.norm(result, axis=0)\n",
    "\n",
    "        # Rotation invariance.\n",
    "        result = np.mean(result, axis=2) if orthogonal_rot else np.mean(result, axis=1)\n",
    "\n",
    "        # Aggregate orthogonal rotation\n",
    "        result = np.mean(result, axis=0) if orthogonal_rot else result\n",
    "            \n",
    "        return np.swapaxes(result, 1, 3)\n",
    "\n",
    "\n",
    "    def gabor_filtering(self, input_images:Union[np.ndarray, sitk.Image], ndims: int = 3, size: int = 5, sigma: float = 10, lamb: float = 0, gamma: float = 0, theta: float = 0, orthogonal_rot: bool = False, padding: str = \"symmetric\", average_pooling: bool = False) -> np.ndarray:\n",
    "        \n",
    "        if isinstance(input_images, sitk.Image):\n",
    "            input_images = sitk.GetArrayFromImage(input_images)\n",
    "\n",
    "        input_images = np.expand_dims(input_images.astype(np.float64), axis=0)\n",
    "        \n",
    "        result = self.gabor_filter(ndims, size, input_images, sigma, lamb, gamma, theta, orthogonal_rot, padding)\n",
    "        \n",
    "        if average_pooling:\n",
    "            result = np.squeeze(result)\n",
    "            print(result.shape)\n",
    "            pooled_result = self.average_pooling(result)\n",
    "            print(pooled_result.shape)\n",
    "#             result = self.upsample3d(pooled_result, result.shape)\n",
    "#             print(result.shape)\n",
    "        \n",
    "        return np.squeeze(result)\n",
    "           \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    def laws_filter(self, ndims: int, config: List[str], images: np.ndarray, energy_distance: int = 7,\n",
    "                    rot_invariance: bool = False, orthogonal_rot: bool = False, padding: str = \"symmetric\", energy_image: bool = False) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply Laws filter to the input images.\n",
    "\n",
    "        Args:\n",
    "            ndims (int): Number of dimensions for the filter.\n",
    "            config (List[str]): A list of strings specifying the 1D filters to use.\n",
    "            images (np.ndarray): The input images to be filtered.\n",
    "            energy_distance (int): Distance for creating the energy kernel.\n",
    "            rot_invariance (bool): If true, apply rotation invariance.\n",
    "            orthogonal_rot (bool): If true, apply orthogonal rotation.\n",
    "            padding (str): The type of padding to use.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The filtered images.\n",
    "        \"\"\"\n",
    "        \n",
    "        if images.ndim == 3:  # Assuming the input is a 3D image\n",
    "            images = np.expand_dims(images, axis=0)  # Add batch dimension\n",
    "        elif images.ndim != 4:  # Must be 4D (batch, channels, depth, height, width)\n",
    "            raise ValueError(\"Input images must be a 3D or 4D array.\")\n",
    "\n",
    "        ndims = len(config)\n",
    "        self.config = config\n",
    "        self.energy_dist = energy_distance\n",
    "        self.dim = ndims\n",
    "        self.padding = padding\n",
    "        self.rot = rot_invariance\n",
    "        self.energy_kernel = None\n",
    "\n",
    "        def __get_filter(name,\n",
    "                         pad=False) -> np.ndarray:\n",
    "            \"\"\"This method create a 1D filter according to the given filter name.\n",
    "\n",
    "            Args:\n",
    "                name (float): The filter name. (Such as L3, L5, E3, E5, S3, S5, W5 or R5)\n",
    "                pad (bool): If true, add zero padding of length 1 each side of kernel L3, E3 and S3\n",
    "\n",
    "            Returns:\n",
    "                ndarray: A 1D filter that is needed to construct the Laws kernel.\n",
    "            \"\"\"\n",
    "\n",
    "            if name == \"L3\":\n",
    "                ker = np.array([0, 1, 2, 1, 0]) if pad else np.array([1, 2, 1])\n",
    "                return 1/math.sqrt(6) * ker\n",
    "            elif name == \"L5\":\n",
    "                return 1/math.sqrt(70) * np.array([1, 4, 6, 4, 1])\n",
    "            elif name == \"E3\":\n",
    "                ker = np.array([0, -1, 0, 1, 0]) if pad else np.array([-1, 0, 1])\n",
    "                return 1 / math.sqrt(2) * ker\n",
    "            elif name == \"E5\":\n",
    "                return 1 / math.sqrt(10) * np.array([-1, -2, 0, 2, 1])\n",
    "            elif name == \"S3\":\n",
    "                ker = np.array([0, -1, 2, -1, 0]) if pad else np.array([-1, 2, -1])\n",
    "                return 1 / math.sqrt(6) * ker\n",
    "            elif name == \"S5\":\n",
    "                return 1 / math.sqrt(6) * np.array([-1, 0, 2, 0, -1])\n",
    "            elif name == \"W5\":\n",
    "                return 1 / math.sqrt(10) * np.array([-1, 2, 0, -2, 1])\n",
    "            elif name == \"R5\":\n",
    "                return 1 / math.sqrt(70) * np.array([1, -4, 6, -4, 1])\n",
    "            else:\n",
    "                raise Exception(f\"{name} is not a valid filter name. \"\n",
    "                                \"Choose between : L3, L5, E3, E5, S3, S5, W5 or R5\")\n",
    "                \n",
    "        def __compute_energy_image(self,\n",
    "                                   images: np.ndarray) -> np.ndarray:\n",
    "            \"\"\"Compute the Laws texture energy images as described in (Ref 1).\n",
    "\n",
    "            Args:\n",
    "                images (ndarray): A n-dimensional numpy array that represent the filtered images\n",
    "\n",
    "            Returns:\n",
    "                ndarray: A numpy multi-dimensional array of the Laws texture energy map.\n",
    "            \"\"\"\n",
    "            # If we have a 2D kernel but a 3D images, we swap dimension channel with dimension batch.\n",
    "            images = np.swapaxes(images, 0, 1)\n",
    "\n",
    "            # absolute image intensities are used in convolution\n",
    "            result = fftconvolve(np.abs(images), self.energy_kernel, mode='valid') \n",
    "\n",
    "            if self.dim == 2:\n",
    "                return np.swapaxes(result, axis1=0, axis2=1)\n",
    "            else:\n",
    "                return np.squeeze(result, axis=1)\n",
    "            \n",
    "        def create_energy_kernel(energy_dist) -> np.ndarray:\n",
    "            \"\"\"Create the kernel that will be used to generate Laws texture energy images\n",
    "\n",
    "            Returns:\n",
    "                ndarray: A numpy multi-dimensional arrays that represent the Laws energy kernel.\n",
    "            \"\"\"\n",
    "\n",
    "            # Initialize the kernel as tensor of zeros\n",
    "            kernel = np.zeros([self.energy_dist*2+1 for _ in range(self.dim)])\n",
    "\n",
    "            for k in product(range(self.energy_dist*2 + 1), repeat=self.dim):\n",
    "                position = np.array(k)-self.energy_dist\n",
    "                kernel[k] = 1 if np.max(abs(position)) <= self.energy_dist else 0\n",
    "\n",
    "            return np.expand_dims(kernel/np.prod(kernel.shape), axis=(0, 1))\n",
    "            \n",
    "\n",
    "        ker_length = np.array([int(name[-1]) for name in self.config])\n",
    "\n",
    "        pad = not(ker_length.min == ker_length.max)\n",
    "        \n",
    "        filter_list = np.array([[__get_filter(name, pad) for name in self.config]])\n",
    "\n",
    "        if self.rot:\n",
    "            filter_list = np.concatenate((filter_list, np.flip(filter_list, axis=2)), axis=0)\n",
    "            prod_list = [prod for prod in product(*np.swapaxes(filter_list, 0, 1))]\n",
    "\n",
    "            perm_list = []\n",
    "            for i in range(len(prod_list)):\n",
    "                perm_list.extend([perm for perm in permutations(prod_list[i])])\n",
    "\n",
    "            filter_list = np.unique(perm_list, axis=0)\n",
    "\n",
    "        kernel_list = []\n",
    "        for perm in filter_list:\n",
    "            kernel = perm[0]\n",
    "            shape = kernel.shape\n",
    "\n",
    "            for i in range(1, len(perm)):\n",
    "                sub_kernel = perm[i]\n",
    "                shape += np.shape(sub_kernel)\n",
    "                kernel = np.outer(sub_kernel, kernel).reshape(shape)\n",
    "            if self.dim == 3:\n",
    "                kernel_list.extend([np.expand_dims(np.flip(kernel, axis=(1, 2)), axis=0)])\n",
    "            else:\n",
    "                kernel_list.extend([np.expand_dims(np.flip(kernel, axis=(0, 1)), axis=0)])\n",
    "\n",
    "        kernel = np.unique(kernel_list, axis=0)\n",
    "        \n",
    "        energy_kernel = create_energy_kernel(self.energy_dist)\n",
    "        \n",
    "        print(images.shape)\n",
    "        print(kernel.shape)\n",
    "        \n",
    "                    \n",
    "        images = np.swapaxes(images, 1, 3)\n",
    "\n",
    "        if orthogonal_rot:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        result = convolve(self.dim, kernel, images, orthogonal_rot, self.padding)\n",
    "        result = np.amax(result, axis=1) if self.dim == 2 else np.amax(result, axis=0)\n",
    "        \n",
    "        if energy_image:\n",
    "            # We pad the response map\n",
    "            result = np.expand_dims(result, axis=1) if self.dim == 3 else result\n",
    "            ndims = len(result.shape)\n",
    "\n",
    "            padding = [self.energy_dist for _ in range(2 * self.dim)]\n",
    "            pad_axis_list = [i for i in range(ndims - self.dim, ndims)]\n",
    "\n",
    "            response = pad_imgs(result, padding, pad_axis_list, self.padding)\n",
    "\n",
    "            # Free memory\n",
    "            del result\n",
    "\n",
    "            # We compute the energy map and we squeeze the second dimension of the energy maps.\n",
    "            energy_imgs = self.__compute_energy_image(response)\n",
    "\n",
    "            return np.swapaxes(energy_imgs, 1, 3)\n",
    "        else:\n",
    "            return np.swapaxes(result, 1, 3)\n",
    "\n",
    "\n",
    "    def laws_filtering(self, input_images: Union[np.ndarray, sitk.Image], ndims: int = 3, config = ['E5', 'L5', 'S5'], energy_distance: int = 7, rot_invariance: bool = False, orthogonal_rot: bool = False, padding: str = \"constant\", energy_image = False, max_pooling: bool = False) -> np.ndarray:\n",
    "        if isinstance(input_images, sitk.Image):\n",
    "            input_images = sitk.GetArrayFromImage(input_images)\n",
    "\n",
    "        input_images = np.expand_dims(input_images.astype(np.float64), axis=0)\n",
    "        \n",
    "        result = self.laws_filter(ndims, config, input_images, energy_distance, rot_invariance, orthogonal_rot=False, padding=\"constant\", energy_image=False)\n",
    "\n",
    "        if max_pooling:\n",
    "            result = np.squeeze(result)\n",
    "            print(result.shape)\n",
    "            pooled_result = self.max_pooling(result)\n",
    "            print(pooled_result.shape)\n",
    "            result = self.upsample3d(pooled_result, result.shape)\n",
    "            print(result.shape)\n",
    "        \n",
    "        return np.squeeze(result)\n",
    "    \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    def wavelet_filter(self, ndims: int, size: int, images: np.ndarray, wavelet_name: str, rot_invariance: bool = False, padding: str = \"symmetric\", level:int = 1, wt_filter: str = \"LHL\") -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply Laws filter to the input images.\n",
    "\n",
    "        Args:\n",
    "            ndims (int): Number of dimensions for the filter.\n",
    "            config (List[str]): A list of strings specifying the 1D filters to use.\n",
    "            images (np.ndarray): The input images to be filtered.\n",
    "            energy_distance (int): Distance for creating the energy kernel.\n",
    "            rot_invariance (bool): If true, apply rotation invariance.\n",
    "            orthogonal_rot (bool): If true, apply orthogonal rotation.\n",
    "            padding (str): The type of padding to use.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The filtered images.\n",
    "        \"\"\"\n",
    "        self.dim = ndims\n",
    "        self.padding = padding\n",
    "        self.rot = rot_invariance\n",
    "        \n",
    "        _filter = wt_filter\n",
    "        wavelet = pywt.Wavelet(wavelet_name)\n",
    "        \n",
    "        self.wavelet = wavelet\n",
    "        kernel_length = max(wavelet.rec_len, wavelet.dec_len)\n",
    "        \n",
    "        image_shape = np.shape(images[0])\n",
    "        level = 1\n",
    "        padding = []\n",
    "        ker_length = kernel_length * level\n",
    "        \n",
    "        for l in image_shape:\n",
    "            padded_length = math.ceil((l + 2*(ker_length-1)) / 2**level) * 2**level - l\n",
    "            padding.extend([math.floor(padded_length/2), math.ceil(padded_length/2)])\n",
    "            \n",
    "        axis_list = [i for i in range(0, self.dim)]\n",
    "\n",
    "        pad_tuple = ()\n",
    "        j=0\n",
    "        for i in range(np.ndim(images[0])):\n",
    "            if i in axis_list:\n",
    "                pad_tuple += ((padding[j], padding[j+1]),) \n",
    "                j +=2\n",
    "            else:\n",
    "                pad_tuple += ((0,0),)\n",
    "        \n",
    "#         print(pad_tuple)\n",
    "#         print(images.shape)\n",
    "        arr = np.pad(images[0], pad_tuple, mode=self.padding)\n",
    "        \n",
    "        images_padded = np.expand_dims(arr, axis=0)\n",
    "        \n",
    "        _index = str().join(['a' if _filter[i] == 'L' else 'd' for i in range(len(_filter))])\n",
    "\n",
    "        if self.rot:\n",
    "            result = []\n",
    "            _index_list = np.unique([str().join(perm) for perm in permutations(_index, self.dim)])\n",
    "\n",
    "            # For each images, we flip each axis.\n",
    "            for image in images:\n",
    "                axis_rot = [comb for j in range(self.dim+1) for comb in combinations(np.arange(self.dim), j)]\n",
    "                images_rot = [np.flip(image, axis) for axis in axis_rot]\n",
    "\n",
    "                res_rot = []\n",
    "                for i in range(len(images_rot)):\n",
    "                    filtered_image = pywt.swtn(images_rot[i], self.wavelet, level=level)[0]\n",
    "                    res_rot.extend([np.flip(filtered_image[j], axis=axis_rot[i]) for j in _index_list])\n",
    "\n",
    "                result.extend([np.mean(res_rot, axis=0)])\n",
    "        else:\n",
    "            result = []\n",
    "            for i in range(len(images)):\n",
    "                coeffs = pywt.swtn(images[i], wavelet, level=level)\n",
    "                filtered_image = coeffs[level - 1]['dad']\n",
    "                result.append(filtered_image)\n",
    "                \n",
    "#             return np.array(result)\n",
    "\n",
    "        return np.swapaxes(result, 1, 2)\n",
    "\n",
    "            \n",
    "    def wavelet_filtering(self, input_images: Union[np.ndarray, sitk.Image], ndims: int = 3, size: int = 5, wavelet_name: str =\"haar\", rot_invariance: bool = False, padding: str = \"constant\", level: int = 1, average_pooling: bool = False, wt_filter: str = \"LHL\") -> np.ndarray:\n",
    "        \n",
    "        if isinstance(input_images, sitk.Image):\n",
    "            input_images = sitk.GetArrayFromImage(input_images)\n",
    "\n",
    "        input_images = np.expand_dims(input_images.astype(np.float64), axis=0)\n",
    "        \n",
    "        result = self.wavelet_filter(ndims, size, input_images, wavelet_name, rot_invariance, padding, level, wt_filter)\n",
    "\n",
    "        if average_pooling:\n",
    "            result = np.squeeze(result)\n",
    "            print(result.shape)\n",
    "            pooled_result = self.average_pooling(result)\n",
    "            print(pooled_result.shape)\n",
    "#             result = self.upsample3d(pooled_result, result.shape)\n",
    "#             print(result.shape)\n",
    "\n",
    "        return np.squeeze(result)\n",
    "        \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    def riesz_transform(self, image: np.ndarray, l: tuple, aligned_str_tensor: bool = False, sigma_tensor: float = None) -> np.ndarray:\n",
    "        \"\"\"Compute Riesz transform of an input image.\"\"\"\n",
    "        fft_image = np.fft.fftn(image)\n",
    "\n",
    "        if image.ndim < 3:\n",
    "            raise ValueError(\"Input image must have at least three dimensions.\")\n",
    "\n",
    "        nx, ny, nz = image.shape[-3:]\n",
    "\n",
    "        kx = np.fft.fftfreq(nx).reshape(-1, 1, 1)\n",
    "        ky = np.fft.fftfreq(ny).reshape(1, -1, 1)\n",
    "        kz = np.fft.fftfreq(nz).reshape(1, 1, -1)\n",
    "\n",
    "        if aligned_str_tensor:\n",
    "            gradient_filter = sitk.GradientRecursiveGaussianImageFilter()\n",
    "            gradient_filter.SetSigma(sigma_tensor)\n",
    "            gradient = gradient_filter.Execute(sitk.GetImageFromArray(image))\n",
    "\n",
    "            gradient_np = sitk.GetArrayFromImage(gradient)\n",
    "            # Verify gradient_np shape here: (3, nx, ny, nz)\n",
    "\n",
    "            J = np.zeros((3, 3, *gradient_np.shape[:3]))\n",
    "\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    J[i, j] = gradient_np[..., i] * gradient_np[..., j]\n",
    "\n",
    "            # Verify J tensor shape here: (3, 3, nx, ny, nz)\n",
    "\n",
    "            tensor_eigenvalues, tensor_eigenvectors = np.linalg.eigh(J)\n",
    "            dominant_eigenvector = tensor_eigenvectors[..., -1]  # Select the dominant eigenvector\n",
    "            # Adjust transpose or reshape as needed:\n",
    "            dominant_eigenvector = dominant_eigenvector.transpose(2, 0, 1)  # Or try other combinations\n",
    "\n",
    "            kx = kx * dominant_eigenvector[0] + ky * dominant_eigenvector[1] + kz * dominant_eigenvector[2]\n",
    "            ky = kx * dominant_eigenvector[1] + ky * dominant_eigenvector[1] + kz * dominant_eigenvector[2]\n",
    "            kz = kx * dominant_eigenvector[2] + ky * dominant_eigenvector[2] + kz * dominant_eigenvector[2]\n",
    "\n",
    "        riesz_component = l[0] * (1j * kx) + l[1] * (1j * ky) + l[2] * (1j * kz)\n",
    "        riesz_transformed_fft = riesz_component * fft_image\n",
    "        riesz_transformed_image = np.fft.ifftn(riesz_transformed_fft).real\n",
    "\n",
    "        return riesz_transformed_image\n",
    "\n",
    "    def riesz_filtering(self, input_images: np.ndarray, l: tuple, aligned_str_tensor: bool = False, sigma_tensor: float = None) -> np.ndarray:\n",
    "        \"\"\"Apply Riesz transform to input images.\"\"\"\n",
    "        if isinstance(input_images, sitk.Image):\n",
    "            input_images = sitk.GetArrayFromImage(input_images)\n",
    "        \n",
    "        input_images = np.expand_dims(input_images.astype(np.float64), axis=0)\n",
    "\n",
    "        result = self.riesz_transform(input_images, l, aligned_str_tensor, sigma_tensor)\n",
    "        \n",
    "        return np.squeeze(result)\n",
    "    \n",
    "    def riesz_then_log_filtering(self, input_images, l: tuple, aligned_str_tensor: bool = False, sigma_tensor: float = None, ndims: int = 3, size: int = 15, sigma: float = 5.0, padding: str = \"symmetric\") -> np.ndarray:\n",
    "        riesz_image = self.riesz_filtering(input_images, l, aligned_str_tensor, sigma_tensor)\n",
    "        \n",
    "        riesz_image = sitk.GetImageFromArray(riesz_image)\n",
    "        riesz_image.CopyInformation(input_images)\n",
    "        \n",
    "        \n",
    "        log_filtered_image = self.log_filtering(riesz_image, ndims, size, sigma, padding)\n",
    "        \n",
    "        return log_filtered_image\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "c55c1970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered image saved at: /Users/kamleshranabhat/Desktop/test_dataset/pattern_1/image/34.nii\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    filtering = Filtering()\n",
    "\n",
    "    checkerboard_path = \"/Users/kamleshranabhat/Desktop/test_dataset/checkerboard/image/checkerboard.nii\"\n",
    "    impulse_path = \"/Users/kamleshranabhat/Desktop/test_dataset/impulse/image/impulse.nii\"\n",
    "    sphere_path = \"/Users/kamleshranabhat/Desktop/test_dataset/sphere/image/sphere.nii\"\n",
    "    pattern1_path = \"/Users/kamleshranabhat/Desktop/test_dataset/pattern_1/image/pattern_1.nii\"\n",
    "    \n",
    "    output_path = \"/Users/kamleshranabhat/Desktop/test_dataset/pattern_1/image/34.nii\"\n",
    "    \n",
    "    \n",
    "    checkerboard_image = sitk.ReadImage(checkerboard_path)\n",
    "    impulse_image = sitk.ReadImage(impulse_path)\n",
    "    sphere_image = sitk.ReadImage(sphere_path)\n",
    "    pattern1_image = sitk.ReadImage(pattern1_path)\n",
    "\n",
    "#     filtered_image_np = filtering.mean_filtering(impulse_image, ndims=2, size = 15, orthogonal_rot =False, padding = \"constant\" )\n",
    "#     filtered_image_np= filtering.log_filtering(checkerboard_image, ndims=2, size=21, sigma=5, orthogonal_rot=False,padding= 'symmetric')\n",
    "#     filtered_image_np = filtering.gabor_filtering(impulse_image, ndims = 2, size = 15, sigma = 10.0, lamb = 4.0,gamma = 0.5, theta = math.pi/4, orthogonal_rot = False, padding = \"constant\", average_pooling = True)                                               \n",
    "#     filtered_image_np = filtering.laws_filtering(checkerboard_image, ndims=2, config = ['L5','S5'], energy_distance=7, rot_invariance= True, orthogonal_rot= False, padding= 'symmetric', energy_image= False, max_pooling=True)                                          \n",
    "#     filtered_image_np = filtering.wavelet_filtering(checkerboard_image, ndims=3,size=15, wavelet_name = \"sym2\",rot_invariance=False, padding=\"wrap\", level = 1, wt_filter = \"B\", average_pooling = False)\n",
    "    filtered_image_np = filtering.riesz_filtering(pattern1_image, l=(0, 2, 0), sigma_tensor = None, aligned_str_tensor=False)\n",
    "#     checkerboard_image = sitk.ReadImage(output_path)\n",
    "#     filtered_image_np= filtering.log_filtering(checkerboard_image, ndims=3, size=15, sigma=3, orthogonal_rot=False, padding= 'constant')\n",
    "#     filtered_image_np = filtering.wavelet_filtering(checkerboard_image, ndims=3,size=15, wavelet_name = \"sym2\",rot_invariance=False, padding=\"edge\", level = 1, wt_filter = \"B\", average_pooling = False)\n",
    "\n",
    "                                   \n",
    "\n",
    "                        \n",
    "#     filtered_image_np = filtering.log_filtering(checkerboard_image, ndims=3, sigma = 5, padding = \"reflect\" )\n",
    "#     filtered_image_np = filtering.laws_filtering(checkerboard_image, ndims=3, sigma = 5, padding = \"reflect\" )\n",
    "#     filtered_image_np = filtering.gabor_filtering(checkerboard_image, ndims = 2, size = 5, sigma = 10, lamb = 4, gamma = 0.5, theta = math.pi/3, orthogonal_rot = False, padding = \"constant\")\n",
    "#     filtered_image_np = filtering.wavelet_filtering(checkerboard_image, ndims=3, wavelet_name = \"sym2\", rot_invariance=False, padding=\"wrap\", level = 3, wt_filter = \"B\", avg_pooling = False)\n",
    "#     filtered_image_np = filtering.riesz_filtering(checkerboard_image, ndims=3, sigma = 5, padding = \"reflect\" )\n",
    "\n",
    "    \n",
    "    filtered_image_sitk = sitk.GetImageFromArray(filtered_image_np)\n",
    "    filtered_image_sitk.CopyInformation(checkerboard_image)\n",
    "    \n",
    "\n",
    "    print(f\"Filtered image saved at: {output_path}\")\n",
    "    \n",
    "    sitk.WriteImage(filtered_image_sitk, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "410fb216",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[222], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m wavelet \u001b[38;5;241m=\u001b[39m pywt\u001b[38;5;241m.\u001b[39mWavelet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msym2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(images)):\n\u001b[1;32m      4\u001b[0m     coeffs \u001b[38;5;241m=\u001b[39m pywt\u001b[38;5;241m.\u001b[39mswtn(images[i], wavelet, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Print the keys of the wavelet coefficients for debugging\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "wavelet = pywt.Wavelet(\"sym2\")\n",
    "\n",
    "for i in range(len(images)):\n",
    "    coeffs = pywt.swtn(images[i], wavelet, level=1)\n",
    "    # Print the keys of the wavelet coefficients for debugging\n",
    "    print(f\"Available keys in coeffs at level {level-1}: {list(coeffs[level-1].keys())}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1811ca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 64)\n",
      "(7, 70, 70, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_shape = (1, 64, 64, 64)\n",
    "\n",
    "pad_tuple = ((3, 3), (3, 3), (3, 3), (0,0))\n",
    "\n",
    "image = np.random.rand(*image_shape)\n",
    "\n",
    "padded_image = np.pad(image, pad_tuple, mode='constant')\n",
    "\n",
    "print(image.shape)\n",
    "print(padded_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e5cf7a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bior1.1: Biorthogonal\n",
      "bior1.3: Biorthogonal\n",
      "bior1.5: Biorthogonal\n",
      "bior2.2: Biorthogonal\n",
      "bior2.4: Biorthogonal\n",
      "bior2.6: Biorthogonal\n",
      "bior2.8: Biorthogonal\n",
      "bior3.1: Biorthogonal\n",
      "bior3.3: Biorthogonal\n",
      "bior3.5: Biorthogonal\n",
      "bior3.7: Biorthogonal\n",
      "bior3.9: Biorthogonal\n",
      "bior4.4: Biorthogonal\n",
      "bior5.5: Biorthogonal\n",
      "bior6.8: Biorthogonal\n",
      "cgau1: Continuous\n",
      "cgau2: Continuous\n",
      "cgau3: Continuous\n",
      "cgau4: Continuous\n",
      "cgau5: Continuous\n",
      "cgau6: Continuous\n",
      "cgau7: Continuous\n",
      "cgau8: Continuous\n",
      "cmor: Continuous\n",
      "coif1: Coiflets\n",
      "coif2: Coiflets\n",
      "coif3: Coiflets\n",
      "coif4: Coiflets\n",
      "coif5: Coiflets\n",
      "coif6: Coiflets\n",
      "coif7: Coiflets\n",
      "coif8: Coiflets\n",
      "coif9: Coiflets\n",
      "coif10: Coiflets\n",
      "coif11: Coiflets\n",
      "coif12: Coiflets\n",
      "coif13: Coiflets\n",
      "coif14: Coiflets\n",
      "coif15: Coiflets\n",
      "coif16: Coiflets\n",
      "coif17: Coiflets\n",
      "db1: Daubechies\n",
      "db2: Daubechies\n",
      "db3: Daubechies\n",
      "db4: Daubechies\n",
      "db5: Daubechies\n",
      "db6: Daubechies\n",
      "db7: Daubechies\n",
      "db8: Daubechies\n",
      "db9: Daubechies\n",
      "db10: Daubechies\n",
      "db11: Daubechies\n",
      "db12: Daubechies\n",
      "db13: Daubechies\n",
      "db14: Daubechies\n",
      "db15: Daubechies\n",
      "db16: Daubechies\n",
      "db17: Daubechies\n",
      "db18: Daubechies\n",
      "db19: Daubechies\n",
      "db20: Daubechies\n",
      "db21: Daubechies\n",
      "db22: Daubechies\n",
      "db23: Daubechies\n",
      "db24: Daubechies\n",
      "db25: Daubechies\n",
      "db26: Daubechies\n",
      "db27: Daubechies\n",
      "db28: Daubechies\n",
      "db29: Daubechies\n",
      "db30: Daubechies\n",
      "db31: Daubechies\n",
      "db32: Daubechies\n",
      "db33: Daubechies\n",
      "db34: Daubechies\n",
      "db35: Daubechies\n",
      "db36: Daubechies\n",
      "db37: Daubechies\n",
      "db38: Daubechies\n",
      "dmey: Discrete Meyer (FIR Approximation)\n",
      "fbsp: Continuous\n",
      "gaus1: Continuous\n",
      "gaus2: Continuous\n",
      "gaus3: Continuous\n",
      "gaus4: Continuous\n",
      "gaus5: Continuous\n",
      "gaus6: Continuous\n",
      "gaus7: Continuous\n",
      "gaus8: Continuous\n",
      "haar: Haar\n",
      "mexh: Continuous\n",
      "morl: Continuous\n",
      "rbio1.1: Reverse biorthogonal\n",
      "rbio1.3: Reverse biorthogonal\n",
      "rbio1.5: Reverse biorthogonal\n",
      "rbio2.2: Reverse biorthogonal\n",
      "rbio2.4: Reverse biorthogonal\n",
      "rbio2.6: Reverse biorthogonal\n",
      "rbio2.8: Reverse biorthogonal\n",
      "rbio3.1: Reverse biorthogonal\n",
      "rbio3.3: Reverse biorthogonal\n",
      "rbio3.5: Reverse biorthogonal\n",
      "rbio3.7: Reverse biorthogonal\n",
      "rbio3.9: Reverse biorthogonal\n",
      "rbio4.4: Reverse biorthogonal\n",
      "rbio5.5: Reverse biorthogonal\n",
      "rbio6.8: Reverse biorthogonal\n",
      "shan: Continuous\n",
      "sym2: Symlets\n",
      "sym3: Symlets\n",
      "sym4: Symlets\n",
      "sym5: Symlets\n",
      "sym6: Symlets\n",
      "sym7: Symlets\n",
      "sym8: Symlets\n",
      "sym9: Symlets\n",
      "sym10: Symlets\n",
      "sym11: Symlets\n",
      "sym12: Symlets\n",
      "sym13: Symlets\n",
      "sym14: Symlets\n",
      "sym15: Symlets\n",
      "sym16: Symlets\n",
      "sym17: Symlets\n",
      "sym18: Symlets\n",
      "sym19: Symlets\n",
      "sym20: Symlets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c8/106_rczd17x4nxwn9bpg6cw00000gn/T/ipykernel_95794/1847860618.py:12: FutureWarning: Wavelets from the family cmor, without parameters specified in the name are deprecated. The name should takethe form cmorB-C where B and C are floats representing the bandwidth frequency and center frequency, respectively (example: cmor1.5-1.0).\n",
      "  wavelet = pywt.ContinuousWavelet(wavelet_name)\n",
      "/var/folders/c8/106_rczd17x4nxwn9bpg6cw00000gn/T/ipykernel_95794/1847860618.py:12: FutureWarning: Wavelets of family fbsp, without parameters specified in the name are deprecated.  The name should take the form fbspM-B-C where M is the spline order and B, C are floats representing the bandwidth frequency and center frequency, respectively (example: fbsp1-1.5-1.0).\n",
      "  wavelet = pywt.ContinuousWavelet(wavelet_name)\n",
      "/var/folders/c8/106_rczd17x4nxwn9bpg6cw00000gn/T/ipykernel_95794/1847860618.py:12: FutureWarning: Wavelets from the family shan, without parameters specified in the name are deprecated. The name should takethe form shanB-C where B and C are floats representing the bandwidth frequency and center frequency, respectively (example: shan1.5-1.0).\n",
      "  wavelet = pywt.ContinuousWavelet(wavelet_name)\n"
     ]
    }
   ],
   "source": [
    "import pywt\n",
    "\n",
    "wavelet_list = pywt.wavelist()\n",
    "\n",
    "for wavelet_name in wavelet_list:\n",
    "    try:\n",
    "        wavelet = pywt.Wavelet(wavelet_name)\n",
    "        family_name = wavelet.family_name\n",
    "        print(f\"{wavelet_name}: {family_name}\")\n",
    "    except ValueError:\n",
    "        # Handle continuous wavelets separately\n",
    "        wavelet = pywt.ContinuousWavelet(wavelet_name)\n",
    "        family_name = \"Continuous\"\n",
    "        print(f\"{wavelet_name}: {family_name}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0a102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d80a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "impulse_path = \"/Users/kamleshranabhat/Desktop/test_dataset/impulse/image/impulse.nii\"\n",
    "sphere_path = \"/Users/kamleshranabhat/Desktop/test_dataset/sphere/image/sphere.nii\"\n",
    "checkerboard = \"/Users/kamleshranabhat/Desktop/test_dataset/checkerboard/image/checkerboard.nii\"\n",
    "\n",
    "print(math.pi/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ddc7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "import math\n",
    "from itertools import permutations, product\n",
    "\n",
    "\n",
    "class filtering:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.config = None\n",
    "        self.energy_dist = None\n",
    "        self.dim = None\n",
    "        self.padding = None\n",
    "        self.rot = None\n",
    "        self.energy_kernel = None\n",
    "\n",
    "    def laws_filter(self, ndims: int, config: list, images: np.ndarray, energy_distance: int = 7,\n",
    "                    rot_invariance: bool = False, orthogonal_rot: bool = False, padding: str = \"symmetric\", energy_image: bool = False) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply Laws filter to the input images.\n",
    "\n",
    "        Args:\n",
    "            ndims (int): Number of dimensions for the filter.\n",
    "            config (List[str]): A list of strings specifying the 1D filters to use.\n",
    "            images (np.ndarray): The input images to be filtered.\n",
    "            energy_distance (int): Distance for creating the energy kernel.\n",
    "            rot_invariance (bool): If true, apply rotation invariance.\n",
    "            orthogonal_rot (bool): If true, apply orthogonal rotation.\n",
    "            padding (str): The type of padding to use.\n",
    "            energy_image (bool): If true, compute energy image.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The filtered images.\n",
    "        \"\"\"\n",
    "        if images.ndim == 3:\n",
    "            images = np.expand_dims(images, axis=0)  # Add batch dimension\n",
    "        elif images.ndim != 4:\n",
    "            raise ValueError(\"Input images must be a 3D or 4D array.\")\n",
    "\n",
    "        self.config = config\n",
    "        self.energy_dist = energy_distance\n",
    "        self.dim = ndims\n",
    "        self.padding = padding\n",
    "        self.rot = rot_invariance\n",
    "\n",
    "        filter_list = np.array([self.__get_filter(name, pad=(ndims == 3)) for name in config])\n",
    "\n",
    "        if rot_invariance:\n",
    "            filter_list = np.concatenate((filter_list, np.flip(filter_list, axis=-1)), axis=0)\n",
    "            filter_list = np.array([list(prod) for prod in product(*filter_list.T)])\n",
    "        else:\n",
    "            filter_list = np.array([filter_list])\n",
    "\n",
    "        kernel_list = []\n",
    "        for perm in filter_list:\n",
    "            kernel = perm[0]\n",
    "            shape = kernel.shape\n",
    "\n",
    "            for i in range(1, len(perm)):\n",
    "                sub_kernel = perm[i]\n",
    "                shape += np.shape(sub_kernel)\n",
    "                kernel = np.outer(sub_kernel, kernel).reshape(shape)\n",
    "\n",
    "            kernel_list.append(np.expand_dims(kernel, axis=0))\n",
    "\n",
    "        kernel = np.unique(kernel_list, axis=0)\n",
    "\n",
    "        ekernel = np.zeros([energy_distance*2+1 for _ in range(ndims)])\n",
    "        for k in product(range(energy_distance*2 + 1), repeat=ndims):\n",
    "            position = np.array(k) - energy_distance\n",
    "            ekernel[k] = 1 if np.max(abs(position)) <= energy_distance else 0\n",
    "\n",
    "        self.energy_kernel = np.expand_dims(ekernel / np.prod(ekernel.shape), axis=tuple(range(2 * ndims)))\n",
    "\n",
    "        images = np.swapaxes(images, 1, 3)  # Swap axes to match fftconvolve requirement\n",
    "        \n",
    "        print(images.shape)\n",
    "        print(kernel.shape)\n",
    "\n",
    "        result = []\n",
    "        for img in images:\n",
    "            conv_result = np.array([fftconvolve(img, k, mode='same') for k in kernel])\n",
    "            result.append(np.amax(conv_result, axis=0))\n",
    "\n",
    "        result = np.array(result)\n",
    "\n",
    "        if energy_image:\n",
    "            # Compute energy image if required\n",
    "            energy_imgs = self.__compute_energy_image(result)\n",
    "            return np.swapaxes(energy_imgs, 1, 3)\n",
    "        else:\n",
    "            return np.swapaxes(result, 1, 3)\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_filter(name, pad=False) -> np.ndarray:\n",
    "        if name == \"L3\":\n",
    "            ker = np.array([0, 1, 2, 1, 0]) if pad else np.array([1, 2, 1])\n",
    "            return 1 / math.sqrt(6) * ker\n",
    "        elif name == \"L5\":\n",
    "            return 1 / math.sqrt(70) * np.array([1, 4, 6, 4, 1])\n",
    "        elif name == \"E3\":\n",
    "            ker = np.array([0, -1, 0, 1, 0]) if pad else np.array([-1, 0, 1])\n",
    "            return 1 / math.sqrt(2) * ker\n",
    "        elif name == \"E5\":\n",
    "            return 1 / math.sqrt(10) * np.array([-1, -2, 0, 2, 1])\n",
    "        elif name == \"S3\":\n",
    "            ker = np.array([0, -1, 2, -1, 0]) if pad else np.array([-1, 2, -1])\n",
    "            return 1 / math.sqrt(6) * ker\n",
    "        elif name == \"S5\":\n",
    "            return 1 / math.sqrt(6) * np.array([-1, 0, 2, 0, -1])\n",
    "        elif name == \"W5\":\n",
    "            return 1 / math.sqrt(10) * np.array([-1, 2, 0, -2, 1])\n",
    "        elif name == \"R5\":\n",
    "            return 1 / math.sqrt(70) * np.array([1, -4, 6, -4, 1])\n",
    "        else:\n",
    "            raise ValueError(f\"{name} is not a valid filter name. Choose between: L3, L5, E3, E5, S3, S5, W5, or R5.\")\n",
    "\n",
    "    def __compute_energy_image(self, images: np.ndarray) -> np.ndarray:\n",
    "        images = np.swapaxes(images, 0, 1)\n",
    "        result = fftconvolve(np.abs(images), self.energy_kernel, mode='valid')\n",
    "        return np.swapaxes(result, 0, 1)\n",
    "        \n",
    "    def laws_filtering(self, input_images: Union[np.ndarray, sitk.Image], ndims: int = 3, config = ['E5', 'L5', 'S5'], energy_distance: int = 7, rot_invariance: bool = False, orthogonal_rot: bool = False, padding: str = \"constant\", energy_image = False, max_pooling: bool = False) -> np.ndarray:\n",
    "        if isinstance(input_images, sitk.Image):\n",
    "            input_images = sitk.GetArrayFromImage(input_images)\n",
    "\n",
    "\n",
    "\n",
    "        if isinstance(input_images, sitk.Image):\n",
    "            input_images = sitk.GetArrayFromImage(input_images)\n",
    "\n",
    "        input_images = np.expand_dims(input_images.astype(np.float64), axis=0)\n",
    "\n",
    "        result = self.laws_filter(ndims, config, input_images, energy_distance, rot_invariance, orthogonal_rot=False, padding=\"constant\", energy_image=False)\n",
    "\n",
    "        if max_pooling:\n",
    "            result = self.max_pooling(result, pool_size=2)  # Adjust the pool_size as needed\n",
    "\n",
    "        return np.squeeze(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63afd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filtering = filtering()\n",
    "\n",
    "    checkerboard_path = \"/Users/kamleshranabhat/Desktop/test_dataset/checkerboard/image/checkerboard.nii\"\n",
    "    checkerboard_image = sitk.ReadImage(checkerboard_path)\n",
    "#     checkerboard_image = sitk.GetImageFromArray(filtered_image_np)\n",
    "\n",
    "#     filtered_image_np = filtering.gabor_filtering(checkerboard_image, ndims = 2, size = 5, sigma = 10, lamb = 4, gamma = 0.5, theta = math.pi/3, orthogonal_rot = False, padding = \"constant\")\n",
    "    \n",
    "    filtered_image_np = filtering.laws_filtering(checkerboard_image, ndims=3, config=['E5', 'L5', 'S5'], energy_distance=7, rot_invariance=True, orthogonal_rot=False, padding=\"symmetric\", energy_image = True, max_pooling=True)\n",
    "\n",
    "    # Convert back to SimpleITK image if needed\n",
    "    filtered_image_sitk = sitk.GetImageFromArray(filtered_image_np)\n",
    "    filtered_image_sitk.CopyInformation(checkerboard_image)\n",
    "    \n",
    "    output_path = \"/Users/kamleshranabhat/Desktop/test_dataset/checkerboard/image/3D_mirrorpadding_rotinvariance_maxpooling_energymap_lawsfiltered_checkerboard.nii\"\n",
    "    \n",
    "    sitk.WriteImage(filtered_image_sitk, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8796faf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "convolve() missing 1 required positional argument: 'images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m aligned_str_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m sigma_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m filtered_image_np \u001b[38;5;241m=\u001b[39m filtering\u001b[38;5;241m.\u001b[39mriesz_then_log_filtering(\n\u001b[1;32m     12\u001b[0m     checkerboard_image, \n\u001b[1;32m     13\u001b[0m     l\u001b[38;5;241m=\u001b[39ml, \n\u001b[1;32m     14\u001b[0m     aligned_str_tensor\u001b[38;5;241m=\u001b[39maligned_str_tensor, \n\u001b[1;32m     15\u001b[0m     sigma_tensor\u001b[38;5;241m=\u001b[39msigma_tensor, \n\u001b[1;32m     16\u001b[0m     ndims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[1;32m     17\u001b[0m     size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[1;32m     18\u001b[0m     sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[1;32m     19\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m filtered_image_sitk \u001b[38;5;241m=\u001b[39m sitk\u001b[38;5;241m.\u001b[39mGetImageFromArray(filtered_image_np)\n\u001b[1;32m     23\u001b[0m filtered_image_sitk\u001b[38;5;241m.\u001b[39mCopyInformation(checkerboard_image)\n",
      "Cell \u001b[0;32mIn[27], line 101\u001b[0m, in \u001b[0;36mFiltering.riesz_then_log_filtering\u001b[0;34m(self, input_images, l, aligned_str_tensor, sigma_tensor, ndims, size, sigma, padding)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mriesz_then_log_filtering\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_images: Union[np\u001b[38;5;241m.\u001b[39mndarray, sitk\u001b[38;5;241m.\u001b[39mImage], l: \u001b[38;5;28mtuple\u001b[39m, aligned_str_tensor: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, sigma_tensor: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, ndims: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, sigma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5.0\u001b[39m, padding: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    100\u001b[0m     riesz_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mriesz_transform(input_images, l, aligned_str_tensor, sigma_tensor)\n\u001b[0;32m--> 101\u001b[0m     log_filtered_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_filtering(riesz_image, ndims, size, sigma, padding)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_filtered_image\n",
      "Cell \u001b[0;32mIn[27], line 43\u001b[0m, in \u001b[0;36mFiltering.log_filtering\u001b[0;34m(self, input_images, ndims, size, sigma, orthogonal_rot, padding)\u001b[0m\n\u001b[1;32m     39\u001b[0m     input_images \u001b[38;5;241m=\u001b[39m sitk\u001b[38;5;241m.\u001b[39mGetArrayFromImage(input_images)\n\u001b[1;32m     41\u001b[0m input_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(input_images\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_filter(ndims, size, input_images, sigma, orthogonal_rot, padding)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     46\u001b[0m     crop \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)]\n",
      "Cell \u001b[0;32mIn[27], line 33\u001b[0m, in \u001b[0;36mFiltering.log_filter\u001b[0;34m(self, ndims, size, images, sigma, orthogonal_rot, padding)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput images must have at least 4 dimensions (B, W, H, D)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mswapaxes(images, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(convolve(images, kernel, mode\u001b[38;5;241m=\u001b[39mpadding), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mswapaxes(result, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: convolve() missing 1 required positional argument: 'images'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filtering = Filtering()\n",
    "\n",
    "    checkerboard_path = \"/Users/kamleshranabhat/Desktop/test_dataset/impulse/image/impulse.nii\"\n",
    "    checkerboard_image = sitk.ReadImage(checkerboard_path)\n",
    "    \n",
    "    l = (1, 0, 0)\n",
    "    aligned_str_tensor = False\n",
    "    sigma_tensor = 1.0\n",
    "\n",
    "    filtered_image_np = filtering.riesz_then_log_filtering(\n",
    "        checkerboard_image, \n",
    "        l=l, \n",
    "        aligned_str_tensor=aligned_str_tensor, \n",
    "        sigma_tensor=sigma_tensor, \n",
    "        ndims=3, \n",
    "        size=5, \n",
    "        sigma=3, \n",
    "        padding=\"constant\"\n",
    "    )\n",
    "\n",
    "    filtered_image_sitk = sitk.GetImageFromArray(filtered_image_np)\n",
    "    filtered_image_sitk.CopyInformation(checkerboard_image)\n",
    "    \n",
    "    output_path = \"/Users/kamleshranabhat/Desktop/test_dataset/impulse/image/zeropadding_rieszlogfiltered_100_impulse.nii\"\n",
    "    \n",
    "    sitk.WriteImage(filtered_image_sitk, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91320753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5d577ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from itertools import product\n",
    "import math\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "class Filtering:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def log_filter(self, ndims:int, size: int, images: np.ndarray, sigma: float, orthogonal_rot: bool = False, padding=\"constant\") -> np.ndarray:\n",
    "        \"\"\"The constructor of the laplacian of gaussian (LoG) filter\n",
    "\n",
    "        Args:\n",
    "            ndims (int): Number of dimension of the kernel filter\n",
    "            size (int): An integer that represent the length along one dimension of the kernel.\n",
    "            sigma (float): The gaussian standard deviation parameter of the laplacian of gaussian filter\n",
    "            padding (str): The padding type that will be used to produce the convolution\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        assert isinstance(ndims, int) and ndims > 0, \"ndims should be a positive integer\"\n",
    "        assert ((size+1)/2).is_integer() and size > 0, \"size should be a positive odd number.\"\n",
    "        assert sigma > 0, \"alpha should be a positive float.\"\n",
    "        self.dim = ndims\n",
    "        self.size = size\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        def compute_weight(position):\n",
    "            distance_2 = np.sum(position**2)\n",
    "            first_part = -1/((2*math.pi)**(self.dim/2) * self.sigma**(self.dim+2))\n",
    "            second_part = (self.dim - distance_2/self.sigma**2)*math.e**(-distance_2/(2 * self.sigma**2))\n",
    "\n",
    "            return first_part * second_part\n",
    "\n",
    "        kernel = np.zeros([self.size for _ in range(self.dim)])\n",
    "\n",
    "        for k in product(range(self.size), repeat=self.dim):\n",
    "            kernel[k] = compute_weight(np.array(k)-int((self.size-1)/2))\n",
    "\n",
    "        kernel -= np.sum(kernel)/np.prod(kernel.shape)\n",
    "        kernel = np.expand_dims(kernel, axis=(0, 1))\n",
    "        \n",
    "#         # Ensure images is at least 4-dimensional (B, W, H, D)\n",
    "#         if images.ndim < 4:\n",
    "#             raise ValueError(\"Input images must have at least 4 dimensions (B, W, H, D)\")\n",
    "            \n",
    "        print(kernel.shape)\n",
    "\n",
    "        image = np.swapaxes(images, 1, 3)\n",
    "        print(image.shape)\n",
    "        result = np.squeeze(convolve(ndims, kernel, image, orthogonal_rot, padding), axis=1)\n",
    "        \n",
    "        return np.swapaxes(result, 1, 3)\n",
    "        \n",
    "\n",
    "    def log_filtering(self, input_images:Union[np.ndarray, sitk.Image], ndims: int = 3, size: int = 15, sigma: int = 3, orthogonal_rot: bool = False, padding: str = \"symmetric\") -> np.ndarray:\n",
    "        \n",
    "        if isinstance(input_images, sitk.Image):\n",
    "            input_images = sitk.GetArrayFromImage(input_images)\n",
    "\n",
    "        input_images = np.expand_dims(input_images.astype(np.float64), axis=0)\n",
    "        \n",
    "        result = self.log_filter(ndims, size, input_images, sigma, orthogonal_rot, padding)\n",
    "        \n",
    "        return np.squeeze(result)\n",
    "\n",
    "    def riesz_transform(self, image: np.ndarray, l: tuple, aligned_str_tensor: bool = False, sigma_tensor: float = None) -> np.ndarray:\n",
    "        \"\"\"Compute Riesz transform of an input image.\"\"\"\n",
    "        fft_image = np.fft.fftn(image)\n",
    "\n",
    "        # Check image dimensions\n",
    "        if image.ndim < 3:\n",
    "            raise ValueError(\"Input image must have at least three dimensions.\")\n",
    "\n",
    "        \n",
    "        print(image.shape)\n",
    "        nx, ny, nz = image.shape[-3:]\n",
    "        \n",
    "        kx = np.fft.fftfreq(nx).reshape(-1, 1, 1)\n",
    "        ky = np.fft.fftfreq(ny).reshape(1, -1, 1)\n",
    "        kz = np.fft.fftfreq(nz).reshape(1, 1, -1)\n",
    "\n",
    "        if aligned_str_tensor:\n",
    "            gradient_filter = sitk.GradientRecursiveGaussianImageFilter()\n",
    "            gradient_filter.SetSigma(sigma_tensor)\n",
    "            gradient = gradient_filter.Execute(sitk.GetImageFromArray(image))\n",
    "\n",
    "            gradient_np = sitk.GetArrayFromImage(gradient)\n",
    "            J = np.zeros((3, 3, *gradient_np.shape[:3]))\n",
    "\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    J[i, j] = gradient_np[..., i] * gradient_np[..., j]\n",
    "\n",
    "            tensor_eigenvalues, tensor_eigenvectors = np.linalg.eigh(J)\n",
    "            dominant_eigenvector = tensor_eigenvectors[:, :, :, 2]\n",
    "            kx = kx * dominant_eigenvector[0] + ky * dominant_eigenvector[1] + kz * dominant_eigenvector[2]\n",
    "            ky = kx * dominant_eigenvector[1] + ky * dominant_eigenvector[1] + kz * dominant_eigenvector[2]\n",
    "            kz = kx * dominant_eigenvector[2] + ky * dominant_eigenvector[2] + kz * dominant_eigenvector[2]\n",
    "\n",
    "        riesz_component = l[0] * (1j * kx) + l[1] * (1j * ky) + l[2] * (1j * kz)\n",
    "        riesz_transformed_fft = riesz_component * fft_image\n",
    "        riesz_transformed_image = np.fft.ifftn(riesz_transformed_fft).real\n",
    "        \n",
    "        return riesz_transformed_image\n",
    "    \n",
    "    def riesz_filtering(self, input_images: np.ndarray, l: tuple, aligned_str_tensor: bool = False, sigma_tensor: float = None) -> np.ndarray:\n",
    "        \"\"\"Apply Riesz transform to input images.\"\"\"\n",
    "        if isinstance(input_images, sitk.Image):\n",
    "            input_images = sitk.GetArrayFromImage(input_images)\n",
    "        \n",
    "        input_images = np.expand_dims(input_images.astype(np.float64), axis=0)\n",
    "\n",
    "        result = self.riesz_transform(input_images, l, aligned_str_tensor, sigma_tensor)\n",
    "        \n",
    "        return np.squeeze(result)\n",
    "    \n",
    "    def riesz_then_log_filtering(self, input_images, l: tuple, aligned_str_tensor: bool = False, sigma_tensor: float = None, ndims: int = 3, size: int = 4, sigma: float = 5.0, padding: str = \"symmetric\") -> np.ndarray:\n",
    "        riesz_image = self.riesz_filtering(input_images, l, aligned_str_tensor, sigma_tensor)\n",
    "        \n",
    "        riesz_image = sitk.GetImageFromArray(riesz_image)\n",
    "        riesz_image.CopyInformation(input_images)\n",
    "        \n",
    "        log_filtered_image = self.log_filtering(riesz_image, ndims, size, sigma, padding)\n",
    "        \n",
    "        return log_filtered_image\n",
    "\n",
    "# , ndims=3, size=5, sigma=3, padding=\"constant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e76bea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 70, 70, 70)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception thrown in SimpleITK Image_CopyInformation: /tmp/SimpleITK/Code/Common/src/sitkImage.cxx:308:\nsitk::ERROR: Source image size of [ 64, 64, 64 ] does not match this image's size of [ 70, 70, 560 ]!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c8/106_rczd17x4nxwn9bpg6cw00000gn/T/ipykernel_95794/1393835077.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfiltered_image_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwavelet_filtering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckerboard_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwavelet_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sym2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_invariance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwt_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_pooling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfiltered_image_sitk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetImageFromArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_image_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfiltered_image_sitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyInformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckerboard_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/kamleshranabhat/Desktop/test_dataset/impulse/image/zeropadding_rieszthenSimoncellifiltered_100_impulse.nii\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, srcImage)\u001b[0m\n\u001b[1;32m   3424\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3427\u001b[0m         \"\"\"\n\u001b[0;32m-> 3428\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage_CopyInformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrcImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception thrown in SimpleITK Image_CopyInformation: /tmp/SimpleITK/Code/Common/src/sitkImage.cxx:308:\nsitk::ERROR: Source image size of [ 64, 64, 64 ] does not match this image's size of [ 70, 70, 560 ]!"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filtering = Filtering()\n",
    "\n",
    "    checkerboard_path = \"/Users/kamleshranabhat/Desktop/test_dataset/impulse/image/zeropadding_rieszfiltered_100_impulse.nii\"\n",
    "    checkerboard_image = sitk.ReadImage(checkerboard_path)\n",
    "\n",
    "    l = (0, 2, 0)\n",
    "    aligned_str_tensor = True\n",
    "    sigma_tensor = 1.0\n",
    "\n",
    "    filtered_image_np = filtering.wavelet_filtering(checkerboard_image, ndims=3, wavelet_name = \"sym2\", rot_invariance=False, padding=\"constant\", level = 1, wt_filter = \"B\", avg_pooling = False)\n",
    "\n",
    "    filtered_image_sitk = sitk.GetImageFromArray(filtered_image_np)\n",
    "    filtered_image_sitk.CopyInformation(checkerboard_image)\n",
    "\n",
    "    output_path = \"/Users/kamleshranabhat/Desktop/test_dataset/impulse/image/zeropadding_rieszthenSimoncellifiltered_100_impulse.nii\"\n",
    "\n",
    "    sitk.WriteImage(filtered_image_sitk, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    filtering = Filtering()\n",
    "\n",
    "    checkerboard_path = \"/Users/kamleshranabhat/Desktop/test_dataset/sphere/image/zeropadding_rieszfiltered_020_sphere.nii\"\n",
    "    checkerboard_image = sitk.ReadImage(checkerboard_path)\n",
    "\n",
    "    l = (0, 2, 0)\n",
    "    aligned_str_tensor = False\n",
    "    sigma_tensor = 1.0\n",
    "\n",
    "    filtered_image_np = filtering.log_filtering(checkerboard_image, ndims=3, size=5, sigma=3, padding=\"constant\")\n",
    "\n",
    "    filtered_image_sitk = sitk.GetImageFromArray(filtered_image_np)\n",
    "    filtered_image_sitk.CopyInformation(checkerboard_image)\n",
    "\n",
    "    output_path = \"/Users/kamleshranabhat/Desktop/test_dataset/sphere/image/zeropadding_rieszthenlogfiltered_020_sphere.nii\"\n",
    "\n",
    "    sitk.WriteImage(filtered_image_sitk, output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3b14e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class filtering:\n",
    "    def log_filter(self, ndims:int, size: int, images: np.ndarray, sigma: float, orthogonal_rot: bool = False, padding=\"constant\") -> np.ndarray:\n",
    "        \"\"\"The constructor of the laplacian of gaussian (LoG) filter\n",
    "\n",
    "        Args:\n",
    "            ndims (int): Number of dimension of the kernel filter\n",
    "            size (int): An integer that represent the length along one dimension of the kernel.\n",
    "            sigma (float): The gaussian standard deviation parameter of the laplacian of gaussian filter\n",
    "            padding (str): The padding type that will be used to produce the convolution\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        assert isinstance(ndims, int) and ndims > 0, \"ndims should be a positive integer\"\n",
    "        assert ((size+1)/2).is_integer() and size > 0, \"size should be a positive odd number.\"\n",
    "        assert sigma > 0, \"alpha should be a positive float.\"\n",
    "        self.dim = ndims\n",
    "        self.size = size\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        def compute_weight(position):\n",
    "            distance_2 = np.sum(position**2)\n",
    "            first_part = -1/((2*math.pi)**(self.dim/2) * self.sigma**(self.dim+2))\n",
    "            second_part = (self.dim - distance_2/self.sigma**2)*math.e**(-distance_2/(2 * self.sigma**2))\n",
    "\n",
    "            return first_part * second_part\n",
    "\n",
    "        kernel = np.zeros([self.size for _ in range(self.dim)])\n",
    "\n",
    "        for k in product(range(self.size), repeat=self.dim):\n",
    "            kernel[k] = compute_weight(np.array(k)-int((self.size-1)/2))\n",
    "\n",
    "        kernel -= np.sum(kernel)/np.prod(kernel.shape)\n",
    "        kernel = np.expand_dims(kernel, axis=(0, 1))\n",
    "        \n",
    "#         # Ensure images is at least 4-dimensional (B, W, H, D)\n",
    "#         if images.ndim < 4:\n",
    "#             raise ValueError(\"Input images must have at least 4 dimensions (B, W, H, D)\")\n",
    "            \n",
    "        print(kernel.shape)\n",
    "\n",
    "        image = np.swapaxes(images, 1, 3)\n",
    "        print(image.shape)\n",
    "        result = np.squeeze(convolve(ndims, kernel, image, orthogonal_rot, padding), axis=1)\n",
    "        \n",
    "        return np.swapaxes(result, 1, 3)\n",
    "        \n",
    "\n",
    "    def log_filtering(self, input_images:Union[np.ndarray, sitk.Image], ndims: int = 3, size: int = 15, sigma: int = 3, orthogonal_rot: bool = False, padding: str = \"symmetric\") -> np.ndarray:\n",
    "        \n",
    "        if isinstance(input_images, sitk.Image):\n",
    "            input_images = sitk.GetArrayFromImage(input_images)\n",
    "\n",
    "        input_images = np.expand_dims(input_images.astype(np.float64), axis=0)\n",
    "        \n",
    "        result = self.log_filter(ndims, size, input_images, sigma, orthogonal_rot, padding)\n",
    "        \n",
    "        return np.squeeze(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c16649a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering=filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6cad2fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 15, 15, 15)\n",
      "(1, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "checkerboard_path = \"/Users/kamleshranabhat/Desktop/test_dataset/checkerboard/image/checkerboard.nii\"\n",
    "checkerboard_image = sitk.ReadImage(checkerboard_path)\n",
    "\n",
    "filtered_image_np = filtering.log_filtering(checkerboard_image, ndims=3, sigma = 5, padding = \"reflect\" )\n",
    "\n",
    "\n",
    "filtered_image_sitk = sitk.GetImageFromArray(filtered_image_np)\n",
    "filtered_image_sitk.CopyInformation(checkerboard_image)\n",
    "\n",
    "output_path = \"/Users/kamleshranabhat/Desktop/test_dataset/checkerboard/image/test.nii\"\n",
    "\n",
    "sitk.WriteImage(filtered_image_sitk, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f8cf39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
